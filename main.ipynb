{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d5e0e126",
   "metadata": {},
   "source": [
    "# **GET MODEL**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "882e4492",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[+] Downloading model: byviz/bylastic_classification_logs\n",
      "[+] Saving model to: D:\\Documents\\UIT\\Nam_4\\NT505_KLTN\\Cyberfortress-Src\\Cyberfortress-ML-Logs-Classification\\model_v2\n",
      "[✓] Model downloaded and saved successfully.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-04 16:00:08.987349: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-12-04 16:00:11.099513: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n"
     ]
    }
   ],
   "source": [
    "!python src/get_model.py --model_dir ./model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "992fe495",
   "metadata": {},
   "source": [
    "# **INSPECT MODEL**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9441b9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "MODEL INSPECTION REPORT\n",
      "================================================================================\n",
      "================================================================================\n",
      "INSPECTION COMPLETED\n",
      "Results saved to: inspect\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "!python src/inspect_model.py --model_dir ./model --output_res ./inspect"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42ec0170",
   "metadata": {},
   "source": [
    "# **QUICK START MODEL**\n",
    "\n",
    "```bash\n",
    "python quick_start.py --model_dir ./model --workers <num_workers>\n",
    "```\n",
    "\n",
    "See `assets/eval_input/simple_ml_input.md` for input data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a85bdb0d",
   "metadata": {},
   "source": [
    "# **PREPARE LOGS FOR MODEL**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37950b62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "BATCH LOG PROCESSOR\n",
      "======================================================================\n",
      "Input:  d:\\Documents\\UIT\\Nam_4\\NT505_KLTN\\Cyberfortress-Src\\Cyberfortress-ML-Logs-Classification\\assets\\eval_logs\\ecs_logs\n",
      "Output: d:\\Documents\\UIT\\Nam_4\\NT505_KLTN\\Cyberfortress-Src\\Cyberfortress-ML-Logs-Classification\\assets\\eval_logs\\processed_logs\n",
      "Files:  9\n",
      "======================================================================\n",
      "\n",
      "[1/9] modsecurity.json\n",
      "    [OK] 49 with ml_input, 0 skipped\n",
      "[2/9] mysql.json\n",
      "    [OK] 25 with ml_input, 0 skipped\n",
      "[3/9] nginx.json\n",
      "    [OK] 7 with ml_input, 60 skipped\n",
      "[4/9] pfsense.json\n",
      "    [OK] 500 with ml_input, 0 skipped\n",
      "[5/9] router.json\n",
      "    [OK] 0 with ml_input, 500 skipped\n",
      "[6/9] suricata.json\n",
      "    [OK] 500 with ml_input, 0 skipped\n",
      "[7/9] wazuh.json\n",
      "    [OK] 500 with ml_input, 0 skipped\n",
      "[8/9] windows.json\n",
      "    [OK] 500 with ml_input, 0 skipped\n",
      "[9/9] zeek.json\n",
      "    [OK] 0 with ml_input, 315 skipped\n",
      "\n",
      "======================================================================\n",
      "SUMMARY\n",
      "======================================================================\n",
      "Files:     9 total, 9 success, 0 failed\n",
      "Documents: 2956 total\n",
      "ML Input:  2081 (70.4%)\n",
      "Skipped:   875 (29.6%)\n",
      "Time:      0.6s (0.1s/file)\n",
      "======================================================================\n",
      "\n",
      "Report: report_20251204_172908.json\n"
     ]
    }
   ],
   "source": [
    "!python src/prepare_ml_ready.py assets/eval_logs/ecs_logs assets/eval_logs/processed_logs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd6232b0",
   "metadata": {},
   "source": [
    "# **EXTRACT LOGS FOR ML**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "853e538c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "ML INPUT EXTRACTOR\n",
      "======================================================================\n",
      "Input directory: d:\\Documents\\UIT\\Nam_4\\NT505_KLTN\\Cyberfortress-Src\\Cyberfortress-ML-Logs-Classification\\assets\\eval_logs\\processed_logs\n",
      "Output file:     d:\\Documents\\UIT\\Nam_4\\NT505_KLTN\\Cyberfortress-Src\\Cyberfortress-ML-Logs-Classification\\assets\\eval_input\\eval_data.txt\n",
      "Found 9 files to process\n",
      "======================================================================\n",
      "\n",
      "[1/9] Processing: modsecurity_ml_input.json\n",
      "    [OK] Extracted 49 ml_input entries\n",
      "[2/9] Processing: mysql_ml_input.json\n",
      "    [OK] Extracted 25 ml_input entries\n",
      "[3/9] Processing: nginx_ml_input.json\n",
      "    [OK] Extracted 7 ml_input entries\n",
      "[4/9] Processing: pfsense_ml_input.json\n",
      "    [OK] Extracted 500 ml_input entries\n",
      "[5/9] Processing: router_ml_input.json\n",
      "    [!] No ml_input fields found\n",
      "[6/9] Processing: suricata_ml_input.json\n",
      "    [OK] Extracted 500 ml_input entries\n",
      "[7/9] Processing: wazuh_ml_input.json\n",
      "    [OK] Extracted 500 ml_input entries\n",
      "[8/9] Processing: windows_ml_input.json\n",
      "    [OK] Extracted 500 ml_input entries\n",
      "[9/9] Processing: zeek_ml_input.json\n",
      "    [!] No ml_input fields found\n",
      "\n",
      "======================================================================\n",
      "CONSOLIDATING DATA\n",
      "======================================================================\n",
      "[OK] Saved TXT simple output: assets\\eval_input\\eval_data.txt\n",
      "[OK] Successfully extracted 2081 ml_input entries\n"
     ]
    }
   ],
   "source": [
    "!python src/extract_logs_for_ml.py assets/eval_logs/processed_logs assets/eval_input/eval_data.txt --simple-txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57a3ecc1",
   "metadata": {},
   "source": [
    "# **EVALUATE MODEL**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e56bdca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "ML MODEL EVALUATOR\n",
      "======================================================================\n",
      "Input file:    d:\\Documents\\UIT\\Nam_4\\NT505_KLTN\\Cyberfortress-Src\\Cyberfortress-ML-Logs-Classification\\assets\\eval_input\\eval_data_2.txt\n",
      "Model path:    d:\\Documents\\UIT\\Nam_4\\NT505_KLTN\\Cyberfortress-Src\\Cyberfortress-ML-Logs-Classification\\model\n",
      "Output dir:    d:\\Documents\\UIT\\Nam_4\\NT505_KLTN\\Cyberfortress-Src\\Cyberfortress-ML-Logs-Classification\\assets\\eval_results\n",
      "CPU workers:   12\n",
      "Device:        CPU (multi-processing)\n",
      "======================================================================\n",
      "\n",
      "Reading input file...\n",
      "[OK] Loaded 92 log entries\n",
      "\n",
      "Starting evaluation with 12 workers...\n",
      "======================================================================\n",
      "Progress: 92/92 (100.0%) | Speed: 3.9 logs/s | ETA: 0.0s\n",
      "======================================================================\n",
      "\n",
      "Saving results...\n",
      "[OK] JSON results saved to: assets\\eval_results\\eval_eval_data_2_20251204_174420.json\n",
      "[OK] TXT summary saved to: assets\\eval_results\\eval_eval_data_2_20251204_174420.txt\n",
      "\n",
      "======================================================================\n",
      "EVALUATION SUMMARY\n",
      "======================================================================\n",
      "Total logs:    92\n",
      "Successful:    92 (100.0%)\n",
      "Failed:        0 (0.0%)\n",
      "Total time:    23.72 seconds\n",
      "Throughput:    3.88 logs/second\n",
      "\n",
      "Avg latency:   311.86 ms\n",
      "P95 latency:   800.24 ms\n",
      "P99 latency:   864.48 ms\n",
      "\n",
      "Prediction distribution:\n",
      "  ERROR          10 ( 10.9%)\n",
      "  WARNING        70 ( 76.1%)\n",
      "  INFO           12 ( 13.0%)\n",
      "\n",
      "Class distribution:\n",
      "  Class 0 (ERROR  ):     10 ( 10.9%)\n",
      "  Class 1 (WARNING):     70 ( 76.1%)\n",
      "  Class 2 (INFO   ):     12 ( 13.0%)\n",
      "======================================================================\n",
      "\n",
      "[OK] Evaluation completed successfully!\n"
     ]
    }
   ],
   "source": [
    "!python src/evaluate_model.py assets/eval_input/eval_data_2.txt 12 assets/eval_results/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5d54928",
   "metadata": {},
   "source": [
    "# **VISUALIZE RESULTS**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b10b666f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OK] Using latest file: assets/eval_results\\eval_eval_data_2_20251204_174420.json\n",
      "[+] Generating visualization...\n",
      "[✓] Visualization completed. Files saved to: assets/eval_charts\n"
     ]
    }
   ],
   "source": [
    "!python src/visualize_results.py --input assets/eval_results/eval_eval_data_*.json --output assets/eval_charts"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
